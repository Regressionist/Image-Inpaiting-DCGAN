{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from skimage import io\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from skimage.transform import rescale\n",
    "from skimage.color import rgb2gray, gray2rgb\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "from torch.utils.data import Dataset, DataLoader, Subset, ConcatDataset, random_split\n",
    "from torchvision import transforms, utils\n",
    "import random\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "from torch.autograd import Variable\n",
    "import time\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import ImageFile\n",
    "ImageFile.LOAD_TRUNCATED_IMAGES = True\n",
    "plt.ion()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataframe=pd.read_csv('list.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def image_transform(image):\n",
    "    #Construct the mask\n",
    "    mask=np.zeros((128,128,3))\n",
    "    mask[48:80,48:80]=1\n",
    "    \n",
    "    image=image/np.amax(image) #All entries of image between 0 and 1\n",
    "    image=rescale(image,0.5,anti_aliasing=True,multichannel=True) # Rescale image to 128*128*3\n",
    "    if (image.shape==mask.shape):\n",
    "        i=np.multiply(image,np.ones(mask.shape)-mask) #Find the unmasked portion\n",
    "        mu=np.zeros((128,128,3))\n",
    "        mu[:,:,0]=np.mean(i[:,:,0]) #Calculate the mean over unmasked portion\n",
    "        mu[:,:,1]=np.mean(i[:,:,1])\n",
    "        mu[:,:,2]=np.mean(i[:,:,2])\n",
    "        im=mu*mask+i #Set the outer pixel of channel to mean value calculated above\n",
    "        gray_img = rgb2gray(mask) \n",
    "        ip=np.dstack((im,gray_img)) #Stack final image with the mask\n",
    "        if (image is not None and ip is not None and mask is not None):\n",
    "            return (image,ip,mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PlacesDataset(Dataset):\n",
    "    def __init__(self,df,img_dir,transform=None):\n",
    "        self.df=df\n",
    "        self.img_dir=img_dir\n",
    "        self.transform=transform\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    def __getitem__(self,idx):\n",
    "        img_path=os.path.join(self.img_dir,'{}'.format(self.df.loc[idx]['image']))\n",
    "        if(img_path is not None):\n",
    "            image=io.imread(img_path)\n",
    "            if (image is not None):\n",
    "                image,tr_image,mask=image_transform(image)\n",
    "                sample={'orig_image':image,'new_image':tr_image,'mask':mask}\n",
    "                if self.transform:\n",
    "                    sample['orig_image']=self.transform(sample['orig_image'])\n",
    "                    sample['new_image']=self.transform(sample['new_image'])\n",
    "                    sample['mask']=self.transform(sample['mask'])\n",
    "        \n",
    "                return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset=PlacesDataset(dataframe,img_dir='images/test_256/',transform=transforms.Compose([transforms.ToTensor()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(0)\n",
    "num_train=len(dataset)\n",
    "indices=list(range(num_train))\n",
    "test_idx = indices[-210:]\n",
    "train_idx = list(set(indices) - set(test_idx))\n",
    "test_data = Subset(dataset,test_idx)\n",
    "train_data=Subset(dataset,train_idx)\n",
    "validation_data,test_data=random_split(test_data,(20,190))\n",
    "a=len(train_data)-75000\n",
    "train_phase_1,train_phase_2,train_phase_3=random_split(train_data,(70000,5000,a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader_p1 = torch.utils.data.DataLoader(train_phase_1,batch_size=100)\n",
    "train_loader_p2 = torch.utils.data.DataLoader(train_phase_2,batch_size=100)\n",
    "train_loader_p3 = torch.utils.data.DataLoader(train_phase_3,batch_size=100)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data,batch_size=1)\n",
    "test_loader = torch.utils.data.DataLoader(test_data,batch_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Generator, self).__init__()\n",
    "        self.conv1=nn.Conv2d(in_channels=4,out_channels=64,kernel_size=3,dilation=1,stride=1,padding=1)\n",
    "        self.norm1=nn.BatchNorm2d(num_features=64)\n",
    "        self.conv2=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=2,dilation=1,stride=2,padding=0)\n",
    "        self.norm2=nn.BatchNorm2d(num_features=128)\n",
    "        self.conv3=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=2,dilation=1,stride=2,padding=0)\n",
    "        self.norm3=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv4=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,dilation=1,stride=1,padding=1)\n",
    "        self.norm4=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv5=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,dilation=2,stride=1,padding=2)\n",
    "        self.norm5=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv6=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,dilation=4,stride=1,padding=4)\n",
    "        self.norm6=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv7=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,dilation=4,stride=1,padding=4)\n",
    "        self.norm7=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv8=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,dilation=8,stride=1,padding=8)\n",
    "        self.norm8=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv9=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,dilation=16,stride=1,padding=16)\n",
    "        self.norm9=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv10=nn.Conv2d(in_channels=256,out_channels=256,kernel_size=3,dilation=1,stride=1,padding=1)\n",
    "        self.norm10=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv11=nn.ConvTranspose2d(in_channels=256,out_channels=128,kernel_size=4,dilation=1,stride=2,padding=1)\n",
    "        self.norm11=nn.BatchNorm2d(num_features=128)\n",
    "        self.conv12=nn.Conv2d(in_channels=128,out_channels=128,kernel_size=3,dilation=1,stride=1,padding=1)\n",
    "        self.norm12=nn.BatchNorm2d(num_features=128)\n",
    "        self.conv13=nn.ConvTranspose2d(in_channels=128,out_channels=64,kernel_size=4,dilation=1,stride=2,padding=1)\n",
    "        self.norm13=nn.BatchNorm2d(num_features=64)\n",
    "        self.conv14=nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,dilation=1,stride=1,padding=1)\n",
    "        self.norm14=nn.BatchNorm2d(num_features=32)\n",
    "        self.conv15=nn.Conv2d(in_channels=32,out_channels=3,kernel_size=3,dilation=1,stride=1,padding=1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.sigm=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=x.type(torch.cuda.FloatTensor)\n",
    "        out=self.conv1(x)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm1(out)\n",
    "        out=self.conv2(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm2(out)\n",
    "        out=self.conv3(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm3(out)\n",
    "        out=self.conv4(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm4(out)\n",
    "        out=self.conv5(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm5(out)\n",
    "        out=self.conv6(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm6(out)\n",
    "        out=self.conv7(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm7(out)\n",
    "        out=self.conv8(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm8(out)\n",
    "        out=self.conv9(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm9(out)\n",
    "        out=self.conv10(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm10(out)\n",
    "        out=self.conv11(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm11(out)\n",
    "        out=self.conv12(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm12(out)\n",
    "        out=self.conv13(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm13(out)\n",
    "        out=self.conv14(out)\n",
    "        out=self.relu(out)\n",
    "        out=self.norm14(out)\n",
    "        \n",
    "        out=self.conv15(out)\n",
    "        out=self.sigm(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.conv1g=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=5,dilation=1,stride=2)\n",
    "        self.norm1g=nn.BatchNorm2d(num_features=32)\n",
    "        self.conv2g=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5,dilation=1,stride=2)\n",
    "        self.norm2g=nn.BatchNorm2d(num_features=64)\n",
    "        self.conv3g=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,dilation=1,stride=2)\n",
    "        self.norm3g=nn.BatchNorm2d(num_features=128)\n",
    "        self.conv4g=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=5,dilation=1,stride=2)\n",
    "        self.norm4g=nn.BatchNorm2d(num_features=256)\n",
    "        self.conv5g=nn.Conv2d(in_channels=256,out_channels=512,kernel_size=5,dilation=1,stride=2)\n",
    "        \n",
    "        self.conv1l=nn.Conv2d(in_channels=3,out_channels=32,kernel_size=5,dilation=1,stride=2)\n",
    "        self.norm1l=nn.BatchNorm2d(num_features=32)\n",
    "        self.conv2l=nn.Conv2d(in_channels=32,out_channels=64,kernel_size=5,dilation=1,stride=2)\n",
    "        self.norm2l=nn.BatchNorm2d(num_features=64)\n",
    "        self.conv3l=nn.Conv2d(in_channels=64,out_channels=128,kernel_size=5,dilation=1,stride=2)\n",
    "        self.norm3l=nn.BatchNorm2d(num_features=128)\n",
    "        self.conv4l=nn.Conv2d(in_channels=128,out_channels=256,kernel_size=5,dilation=1,stride=2)\n",
    "        \n",
    "        self.fc=nn.Linear(768,1)\n",
    "        self.relu=nn.ReLU()\n",
    "        self.sigm=nn.Sigmoid()\n",
    "        \n",
    "    def forward(self,x):\n",
    "        x=x.type(torch.cuda.FloatTensor)\n",
    "        out_g=self.conv1g(x)\n",
    "        out_g=self.relu(out_g)\n",
    "        out_g=self.norm1g(out_g)\n",
    "        out_g=self.conv2g(out_g)\n",
    "        out_g=self.relu(out_g)\n",
    "        out_g=self.norm2g(out_g)\n",
    "        out_g=self.conv3g(out_g)\n",
    "        out_g=self.relu(out_g)\n",
    "        out_g=self.norm3g(out_g)\n",
    "        out_g=self.conv4g(out_g)\n",
    "        out_g=self.relu(out_g)\n",
    "        out_g=self.norm4g(out_g)\n",
    "        out_g=self.conv5g(out_g)\n",
    "        out_g=self.relu(out_g)\n",
    "        out_g=out_g.view(-1,512)\n",
    "        \n",
    "        \n",
    "        y=x[:,:,32:96,32:96]\n",
    "        out_l=self.conv1l(y)\n",
    "        out_l=self.relu(out_l)\n",
    "        out_l=self.norm1l(out_l)\n",
    "        out_l=self.conv2l(out_l)\n",
    "        out_l=self.relu(out_l)\n",
    "        out_l=self.norm2l(out_l)\n",
    "        out_l=self.conv3l(out_l)\n",
    "        out_l=self.relu(out_l)\n",
    "        out_l=self.norm3l(out_l)\n",
    "        out_l=self.conv4l(out_l)\n",
    "        out_l=self.relu(out_l)\n",
    "        out_l=out_l.view(-1,256)\n",
    "        \n",
    "        out=torch.cat((out_g,out_l),1)\n",
    "        out=self.relu(out)\n",
    "        out=self.fc(out)\n",
    "        out=self.sigm(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_discriminator(model,train_loader,d_optimizer,d_criterion,epoch,num_epochs,epochs,rl_d_fake,rl_d_real):\n",
    "    running_loss_real=0\n",
    "    running_loss_fake=0\n",
    "    discriminator.train()\n",
    "    for i,(sample) in enumerate(train_loader):\n",
    "        i_p=Variable(sample['new_image']).to(device)\n",
    "        i_n=Variable(sample['orig_image']).to(device)\n",
    "        mask=Variable(sample['mask']).to(device)\n",
    "        mask=mask.type(torch.cuda.FloatTensor)\n",
    "        i_p=i_p.type(torch.cuda.FloatTensor)\n",
    "        d_optimizer.zero_grad()\n",
    "        i_o=generator(i_p).detach()\n",
    "        i_p[:,:,48:80,48:80]=0\n",
    "        img=torch.mul(i_o,mask)+i_p[:,0:3,:,:]\n",
    "        d_i_o=discriminator(img)\n",
    "        d_i_n=discriminator(i_n)\n",
    "        \n",
    "        loss_real=d_criterion(d_i_n,ones_target(100).to(device))\n",
    "        loss_real.backward()\n",
    "        rl_d_real.append(loss_real.item())\n",
    "        \n",
    "        loss_fake=d_criterion(d_i_o,zeros_target(100).to(device))\n",
    "        loss_fake.backward()\n",
    "        rl_d_fake.append(loss_fake.item())\n",
    "        \n",
    "        d_optimizer.step()\n",
    "        \n",
    "        running_loss_real+=loss_real.item()\n",
    "        running_loss_fake+=loss_fake.item()\n",
    "        if((i+1)%10==0):\n",
    "            print('Epoch: [{}/{}] | Step: [{}/{}] | Loss_Real: {} | Loss_fake: {} | Total loss: {}'.format(epoch+1-epochs, num_epochs, int((i+1)/10),5 , round(running_loss_real/10,6), round(running_loss_fake/10,6), round((running_loss_real+running_loss_fake)/10,6)))\n",
    "            running_loss_real=0\n",
    "            running_loss_fake=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ones_target(size):\n",
    "    '''\n",
    "    Tensor containing ones, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.ones(size, 1))\n",
    "    return data\n",
    "\n",
    "def zeros_target(size):\n",
    "    '''\n",
    "    Tensor containing zeros, with shape = size\n",
    "    '''\n",
    "    data = Variable(torch.zeros(size, 1))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda:0\n"
     ]
    }
   ],
   "source": [
    "generator = Generator()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(device)\n",
    "generator=generator.to(device)\n",
    "g_criterion = nn.MSELoss()\n",
    "g_optimizer = torch.optim.Adam(generator.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "discriminator=Discriminator()\n",
    "discriminator=discriminator.to(device)\n",
    "d_criterion = nn.BCELoss()\n",
    "d_optimizer = torch.optim.Adam(discriminator.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Generator(\n",
       "  (conv1): Conv2d(4, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(64, 128, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(128, 256, kernel_size=(2, 2), stride=(2, 2))\n",
       "  (norm3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (norm4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv5): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(2, 2), dilation=(2, 2))\n",
       "  (norm5): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv6): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "  (norm6): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv7): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(4, 4), dilation=(4, 4))\n",
       "  (norm7): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv8): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(8, 8), dilation=(8, 8))\n",
       "  (norm8): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv9): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(16, 16), dilation=(16, 16))\n",
       "  (norm9): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv10): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (norm10): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv11): ConvTranspose2d(256, 128, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (norm11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv12): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (norm12): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv13): ConvTranspose2d(128, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
       "  (norm13): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv14): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (norm14): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv15): Conv2d(32, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (relu): ReLU()\n",
       "  (sigm): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint = torch.load('Generator/model_7.pth')\n",
    "generator.load_state_dict(checkpoint['model_state_dict'])\n",
    "g_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "epochs_gen = checkpoint['epoch']\n",
    "rl_g = checkpoint['loss']\n",
    "\n",
    "generator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#num_epochs_dis=10\n",
    "#checkpoint = torch.load('Discriminator/dis_model_1.pth')\n",
    "#discriminator.load_state_dict(checkpoint['model_state_dict'])\n",
    "#d_optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
    "#epochs_dis = checkpoint['epoch']\n",
    "#rl_d = checkpoint['loss']\n",
    "\n",
    "#discriminator.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/skimage/transform/_warps.py:105: UserWarning: The default mode, 'constant', will be changed to 'reflect' in skimage 0.15.\n",
      "  warn(\"The default mode, 'constant', will be changed to 'reflect' in \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [1/5] | Step: [1/5] | Loss_Real: 0.280224 | Loss_fake: 0.127712 | Total loss: 0.407936\n",
      "Epoch: [1/5] | Step: [2/5] | Loss_Real: 0.038523 | Loss_fake: 0.034399 | Total loss: 0.072922\n",
      "Epoch: [1/5] | Step: [3/5] | Loss_Real: 0.013744 | Loss_fake: 0.014754 | Total loss: 0.028498\n",
      "Epoch: [1/5] | Step: [4/5] | Loss_Real: 0.011098 | Loss_fake: 0.014285 | Total loss: 0.025383\n",
      "Epoch: [1/5] | Step: [5/5] | Loss_Real: 0.017282 | Loss_fake: 0.033248 | Total loss: 0.05053\n",
      "%---Saving the model---%\n",
      "Epoch: [2/5] | Step: [1/5] | Loss_Real: 0.012198 | Loss_fake: 0.021596 | Total loss: 0.033794\n",
      "Epoch: [2/5] | Step: [2/5] | Loss_Real: 0.010396 | Loss_fake: 0.021831 | Total loss: 0.032227\n",
      "Epoch: [2/5] | Step: [3/5] | Loss_Real: 0.031915 | Loss_fake: 0.016068 | Total loss: 0.047983\n",
      "Epoch: [2/5] | Step: [4/5] | Loss_Real: 0.018862 | Loss_fake: 0.014284 | Total loss: 0.033146\n",
      "Epoch: [2/5] | Step: [5/5] | Loss_Real: 0.009049 | Loss_fake: 0.002206 | Total loss: 0.011255\n",
      "%---Saving the model---%\n",
      "Epoch: [3/5] | Step: [1/5] | Loss_Real: 0.006186 | Loss_fake: 0.010935 | Total loss: 0.017122\n",
      "Epoch: [3/5] | Step: [2/5] | Loss_Real: 0.001099 | Loss_fake: 0.000399 | Total loss: 0.001498\n",
      "Epoch: [3/5] | Step: [3/5] | Loss_Real: 0.002115 | Loss_fake: 0.001629 | Total loss: 0.003745\n",
      "Epoch: [3/5] | Step: [4/5] | Loss_Real: 0.001725 | Loss_fake: 0.004472 | Total loss: 0.006197\n",
      "Epoch: [3/5] | Step: [5/5] | Loss_Real: 0.008554 | Loss_fake: 0.000269 | Total loss: 0.008822\n",
      "%---Saving the model---%\n",
      "Epoch: [4/5] | Step: [1/5] | Loss_Real: 0.003744 | Loss_fake: 0.018585 | Total loss: 0.022329\n",
      "Epoch: [4/5] | Step: [2/5] | Loss_Real: 0.001418 | Loss_fake: 0.002333 | Total loss: 0.003751\n",
      "Epoch: [4/5] | Step: [3/5] | Loss_Real: 0.001537 | Loss_fake: 0.000974 | Total loss: 0.002511\n",
      "Epoch: [4/5] | Step: [4/5] | Loss_Real: 0.001562 | Loss_fake: 0.003678 | Total loss: 0.00524\n",
      "Epoch: [4/5] | Step: [5/5] | Loss_Real: 0.006514 | Loss_fake: 2e-05 | Total loss: 0.006534\n",
      "%---Saving the model---%\n",
      "Epoch: [5/5] | Step: [1/5] | Loss_Real: 0.001033 | Loss_fake: 0.001071 | Total loss: 0.002105\n",
      "Epoch: [5/5] | Step: [2/5] | Loss_Real: 0.001178 | Loss_fake: 0.000332 | Total loss: 0.001511\n",
      "Epoch: [5/5] | Step: [3/5] | Loss_Real: 0.000174 | Loss_fake: 0.000422 | Total loss: 0.000596\n",
      "Epoch: [5/5] | Step: [4/5] | Loss_Real: 0.000123 | Loss_fake: 4e-06 | Total loss: 0.000128\n",
      "Epoch: [5/5] | Step: [5/5] | Loss_Real: 0.00259 | Loss_fake: 0.001485 | Total loss: 0.004075\n",
      "%---Saving the model---%\n"
     ]
    }
   ],
   "source": [
    "num_epochs_dis=5\n",
    "epochs_dis=0\n",
    "rl_d_fake=[]\n",
    "rl_d_real=[]\n",
    "for epoch_dis in range(epochs_dis,num_epochs_dis+epochs_dis):\n",
    "    train_discriminator(discriminator,train_loader_p2,d_optimizer,d_criterion,epoch_dis,num_epochs_dis,epochs_dis,rl_d_fake,rl_d_real)\n",
    "    print ('%---Saving the model---%')\n",
    "    torch.save({\n",
    "            'epoch': int(epoch_dis+1),\n",
    "            'model_state_dict': discriminator.state_dict(),\n",
    "            'optimizer_state_dict': d_optimizer.state_dict(),\n",
    "            'Fake loss': rl_d_fake,\n",
    "            'Real loss': rl_d_real,\n",
    "            },'Discriminator/model_{}.pth'.format(epoch_dis+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(len(rl_d_fake)),rl_d_fake,color='blue')\n",
    "plt.plot(range(len(rl_d_real)),rl_d_real,color='red')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
